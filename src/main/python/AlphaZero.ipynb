{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thymoterdoest/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/thymoterdoest/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/thymoterdoest/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/thymoterdoest/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/thymoterdoest/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/thymoterdoest/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import Dataset_pb2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOARD_SIZE = 9;\n",
    "CHANNELS = 2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = Dataset_pb2.DataSet()\n",
    "f = open('../resources/dataset.bin', \"rb\")\n",
    "data_set.ParseFromString(f.read())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for data_instance in data_set.data:\n",
    "    data.append(data_instance)\n",
    "data = random.sample(data, len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [];\n",
    "values = [];\n",
    "policies = [];\n",
    "for data_instance in data:\n",
    "    states.append(data_instance.state)\n",
    "    values.append(data_instance.value)\n",
    "    policies.append(data_instance.policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = np.array(states)\n",
    "values = np.array(values)\n",
    "policies = np.array(policies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_3d = states.reshape((len(states), BOARD_SIZE, BOARD_SIZE, CHANNELS))\n",
    "# change channels last to channels first format\n",
    "states_3d_NCHW = np.moveaxis(states_3d, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 1, 0, 1, 0, 1, 0, 1],\n",
       "        [0, 0, 1, 1, 0, 0, 1, 0, 0],\n",
       "        [1, 1, 1, 0, 1, 1, 1, 0, 0],\n",
       "        [0, 0, 1, 1, 0, 1, 0, 1, 1],\n",
       "        [0, 1, 0, 0, 0, 1, 0, 1, 0],\n",
       "        [0, 0, 1, 0, 0, 1, 1, 1, 1],\n",
       "        [0, 1, 1, 0, 1, 0, 1, 1, 0],\n",
       "        [1, 1, 1, 0, 0, 1, 1, 0, 1],\n",
       "        [0, 1, 1, 1, 0, 0, 0, 0, 1]],\n",
       "\n",
       "       [[1, 1, 0, 1, 0, 1, 0, 1, 0],\n",
       "        [1, 1, 0, 0, 1, 1, 0, 1, 1],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 1, 1],\n",
       "        [1, 1, 0, 0, 1, 0, 1, 0, 0],\n",
       "        [1, 0, 1, 1, 1, 0, 1, 0, 1],\n",
       "        [1, 1, 0, 1, 1, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 1, 0, 1, 0, 0, 1],\n",
       "        [0, 0, 0, 1, 1, 0, 0, 1, 0],\n",
       "        [1, 0, 0, 0, 1, 1, 1, 1, 0]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_3d_NCHW[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((states_3d, values)).shuffle(10000).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reserve 10,000 samples for validation\n",
    "x_val = states_3d[-10000:]\n",
    "y_val = values[-10000:]\n",
    "x_train = states_3d[:-10000]\n",
    "y_train = values[:-10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CNNModel(Model):\n",
    "#     def __init__(self):\n",
    "#         super(Model, self).__init__()\n",
    "#         self.conv1 = Conv2D(32, 3, padding='same', activation='relu')\n",
    "#         self.pool1 = MaxPool2D((2,2))\n",
    "#         self.conv2 = Conv2D(64, 3, padding='same', activation='relu')\n",
    "#         self.pool2 = MaxPool2D((2,2))\n",
    "#         self.flatten = Flatten()\n",
    "#         self.d1 = Dense(512, activation='relu')\n",
    "#         self.dropout1 = Dropout(0.4)\n",
    "#         self.d2 = Dense(128, activation='relu')\n",
    "#         self.dropout2 = Dropout(0.4)\n",
    "#         self.d3 = Dense(43, activation='softmax')\n",
    "\n",
    "#     def call(self, x):\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.pool1(x)\n",
    "#         x = self.conv2(x)\n",
    "#         x = self.pool2(x)\n",
    "#         x = self.flatten(x)\n",
    "#         x = self.d1(x)\n",
    "#         x = self.dropout1(x)\n",
    "#         x = self.d2(x)\n",
    "#         x = self.dropout2(x)\n",
    "#         x = self.d3(x)\n",
    "#         return x\n",
    "# model = CNNModel()\n",
    "\n",
    "model = models.Sequential()\n",
    "# model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(2, 9, 9)))\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "# model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "\n",
    "model.add(layers.Conv2D(32, activation=\"relu\", kernel_size=(3, 3),\n",
    "                 input_shape=(BOARD_SIZE, BOARD_SIZE, CHANNELS),\n",
    "                 data_format=\"channels_last\",\n",
    "                 padding='same'))\n",
    "model.add(layers.Conv2D(32, activation=\"relu\", kernel_size=(3, 3),\n",
    "                 data_format=\"channels_last\",\n",
    "                 padding='same'))\n",
    "model.add(layers.MaxPooling2D((2, 2), data_format=\"channels_last\"))\n",
    "model.add(layers.Conv2D(64 * 2, activation=\"relu\", kernel_size=(3, 3),\n",
    "                 data_format=\"channels_last\",\n",
    "                 padding='same'))\n",
    "model.add(layers.Conv2D(64 * 2, activation=\"relu\", kernel_size=(3, 3),\n",
    "                 data_format=\"channels_last\",\n",
    "                 padding='same'))\n",
    "model.add(layers.MaxPooling2D((2, 2), data_format=\"channels_last\"))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='tanh'))\n",
    "\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "# model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath='mymodel_{epoch}.h5',\n",
    "        # Path where to save the model\n",
    "        # The two parameters below mean that we will overwrite\n",
    "        # the current checkpoint if and only if\n",
    "        # the `val_loss` score has improved.\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss',\n",
    "        verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/thymoterdoest/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "# Fit model on training data\n",
      "Train on 144259 samples, validate on 36065 samples\n",
      "WARNING:tensorflow:From /Users/thymoterdoest/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/3\n",
      "144256/144259 [============================>.] - ETA: 0s - loss: 0.1195 - acc: 0.6956 - mean_absolute_error: 0.1420\n",
      "Epoch 00001: val_loss improved from inf to 0.01412, saving model to mymodel_1.h5\n",
      "144259/144259 [==============================] - 77s 531us/sample - loss: 0.1194 - acc: 0.6956 - mean_absolute_error: 0.1420 - val_loss: 0.0141 - val_acc: 0.7431 - val_mean_absolute_error: 0.0267\n",
      "Epoch 2/3\n",
      "144256/144259 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.7400 - mean_absolute_error: 0.0239\n",
      "Epoch 00002: val_loss improved from 0.01412 to 0.01282, saving model to mymodel_2.h5\n",
      "144259/144259 [==============================] - 80s 551us/sample - loss: 0.0182 - acc: 0.7400 - mean_absolute_error: 0.0239 - val_loss: 0.0128 - val_acc: 0.7470 - val_mean_absolute_error: 0.0142\n",
      "Epoch 3/3\n",
      "144256/144259 [============================>.] - ETA: 0s - loss: 0.0159 - acc: 0.7413 - mean_absolute_error: 0.0180\n",
      "Epoch 00003: val_loss did not improve from 0.01282\n",
      "144259/144259 [==============================] - 79s 547us/sample - loss: 0.0159 - acc: 0.7413 - mean_absolute_error: 0.0180 - val_loss: 0.0898 - val_acc: 0.7053 - val_mean_absolute_error: 0.0787\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=['accuracy','mae'])\n",
    "# validation_data=(test_images, test_labels)\n",
    "\n",
    "# Train the model by slicing the data into \"batches\"\n",
    "# of size \"batch_size\", and repeatedly iterating over\n",
    "# the entire dataset for a given number of \"epochs\"\n",
    "print('# Fit model on training data')\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=64,\n",
    "                    epochs=3,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "history dict: {'loss': [0.0020016777825467313, 2.497330839640027e-07, 4.964430914252027e-08], 'acc': [0.7449258, 0.7454249, 0.7454249], 'mean_absolute_error': [0.0020172617, 3.7560294e-05, 1.7387269e-05], 'val_loss': [5.050072048655832e-07, 8.20101348738476e-08, 2.0804803639792533e-08], 'val_acc': [0.7474, 0.7474, 0.7474], 'val_mean_absolute_error': [5.1485138e-05, 2.0244155e-05, 1.0548238e-05]}\n",
      "\n",
      "# Evaluate on test data\n",
      "10000/10000 [==============================] - 1s 93us/sample - loss: 2.0805e-08 - acc: 0.7474 - mean_absolute_error: 1.0548e-05\n",
      "test loss, test acc: [2.080480363244911e-08, 0.7474, 1.0548244e-05]\n"
     ]
    }
   ],
   "source": [
    "# The returned \"history\" object holds a record\n",
    "# of the loss values and metric values during training\n",
    "print('\\nhistory dict:', history.history)\n",
    "\n",
    "# Evaluate the model on the test data using `evaluate`\n",
    "print('\\n# Evaluate on test data')\n",
    "results = model.evaluate(x_val, y_val, batch_size=128)\n",
    "print('test loss, test acc:', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Generate predictions for 3 samples\n",
      "predictions shape: [[ 0.9999903 ]\n",
      " [ 0.9953068 ]\n",
      " [ 0.9989241 ]\n",
      " [-0.999984  ]\n",
      " [-0.020319  ]\n",
      " [-0.02061949]\n",
      " [-0.03048742]\n",
      " [-0.9998889 ]\n",
      " [-0.01936808]\n",
      " [ 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on new data using `predict`\n",
    "print('\\n# Generate predictions for 3 samples')\n",
    "predictions = model.predict(x_val[:10])\n",
    "print('predictions shape:', predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')  # creates a HDF5 file 'my_model.h5'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
